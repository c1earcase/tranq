#

<img src="media/4507.png" width="200"> <img src="https://t4.ftcdn.net/jpg/01/26/10/59/360_F_126105961_6vHCTRX2cPOnQTBvx9OSAwRUapYTEmYA.jpg" width=40> [audio](media/1a.mp3) <img src="https://clipart-library.com/img/1269258.png" width=40>

https://github.com/c1earcase/tranq/assets/8038214/f5b093e7-1a45-49fd-87c5-ac0d385bb1a5

https://github.com/OpenTalker/SadTalker

```
python inference.py --driven_audio audio_Vocals.wav --source_image midjourney.jpg
```

<img src="media/4507.png" width=300>  |  <img src="media/5968.png" width=300>
<br/>
<img src="media/8916.png" width=300>  |  <img src="media/2780.png" width=300>

Compare all 4 Generations: https://youtube.com/shorts/Wz1Uv7fSVjw

---
Optional, separate vocals and instrumentals from "song":

https://github.com/tsurumeso/vocal-remover

```
python inference.py --input path/to/an/audio.wav
```

will produce <b>audio_Vocals.wav</b> and audio_Instrumentals.wav

